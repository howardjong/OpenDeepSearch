modules = ["python-3.10"]
run = "python gradio_demo.py"

[nix]
channel = "stable-24_05"

[deployment]
run = ["sh", "-c", "python gradio_demo.py"]

[workflows]
runButton = "Run Example"

[[workflows.workflow]]
name = "Run Demo"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python gradio_demo.py --reranker jina"

[[workflows.workflow]]
name = "Run Demo (Stable)"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "pip install litellm==1.57.5"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python gradio_demo.py --reranker jina"

[[workflows.workflow]]
name = "Run with Gemini Flash"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "pip install litellm==1.57.5"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python gradio_demo.py --reranker jina --model-name \"openrouter/google/gemini-2.0-flash-001\" --orchestrator-model \"openrouter/google/gemini-2.0-flash-001\""

[[workflows.workflow]]
name = "Run with Claude 3.7 Sonnet (Latest)"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "pip install litellm==1.57.5"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python gradio_demo.py --reranker jina --model-name \"anthropic/claude-3-7-sonnet-20250219\" --orchestrator-model \"anthropic/claude-3-7-sonnet-20250219\""

[[workflows.workflow]]
name = "Run Example"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python example.py"

[[workflows.workflow]]
name = "Run Pro Mode Example"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python pro_mode_example.py"

[[workflows.workflow]]
name = "Run Prompt Test"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python promptTest.py"

[[workflows.workflow]]
name = "Run Prompt Test with DeepSeek"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python promptTest.py"

[[workflows.workflow]]
name = "Test Model Parameters"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python test_llm_models.py --model-key deepseek --temperature 0.3 --max-tokens 2048 --query \"What are the key factors that affect pricing strategies for premium services?\""

[[workflows.workflow]]
name = "Test with Perplexity Direct API"
author = 35006224
mode = "sequential"

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python test_llm_models.py --model \"perplexity/sonar\" --query \"What is the optimal pricing strategy for a premium children's camp led by experts?\""

[[ports]]
localPort = 7860
externalPort = 80
